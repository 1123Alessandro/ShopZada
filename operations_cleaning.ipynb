{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "from scripts.load import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning line item products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning line item products\n",
    "df_item_products1 = all['line_item_data_products1.csv']\n",
    "df_item_products2 = all['line_item_data_products2.csv']\n",
    "df_item_products3 = all['line_item_data_products3.parquet']\n",
    "df_item_products3.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining line item product files\n",
    "df_item_products = pd.concat([df_item_products1, df_item_products2, df_item_products3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_item_products.shape)\n",
    "print(df_item_products.nunique())\n",
    "print(df_item_products.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Unnamed: 0 column\n",
    "df_item_products = df_item_products.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicates based on order_id, keep no empty values\n",
    "df_item_products = df_item_products.drop_duplicates(subset=['order_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line item products data cleaned completely, to check:\n",
    "print(df_item_products.shape)\n",
    "print(df_item_products.nunique())\n",
    "print(df_item_products.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning line item prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning line item prices\n",
    "df_item_prices1 = all['line_item_data_prices1.csv']\n",
    "df_item_prices2 = all['line_item_data_prices2.csv']\n",
    "df_item_prices3 = all['line_item_data_prices3.parquet']\n",
    "\n",
    "df_item_prices = pd.concat([df_item_prices1, df_item_prices2, df_item_prices3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_item_prices.shape)\n",
    "print(df_item_prices.nunique())\n",
    "print(df_item_prices.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Unnamed: 0 column\n",
    "df_item_prices = df_item_prices.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize quantity\n",
    "df_item_prices['quantity'] = df_item_prices['quantity'].str.replace('\\D', '', regex=True)\n",
    "df_item_prices['quantity'] = df_item_prices['quantity'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicates based on order_id, keep no empty values\n",
    "df_item_prices = df_item_prices.drop_duplicates(subset=['order_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line item prices data cleaned completely, to check:\n",
    "print(df_item_prices.shape)\n",
    "print(df_item_prices.nunique())\n",
    "print(df_item_prices.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning order data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning order data\n",
    "df_order1 = all['order_data_20200101-20200701.parquet']\n",
    "df_order2 = all['order_data_20200701-20211001.pickle']\n",
    "df_order3 = all['order_data_20211001-20220101.csv']\n",
    "df_order4 = all['order_data_20220101-20221201.xlsx']\n",
    "df_order5 = all['order_data_20221201-20230601.json']\n",
    "df_order6 = all['order_data_20230601-20240101.html'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing useless Unnamed: 0 column\n",
    "df_order3 = df_order3.drop('Unnamed: 0', axis=1)\n",
    "df_order4 = df_order4.drop('Unnamed: 0', axis=1)\n",
    "df_order6 = df_order6.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all order data\n",
    "df_orders = pd.concat([df_order1, df_order2, df_order3, df_order4, df_order5, df_order6])\n",
    "print(df_orders.shape)\n",
    "print(df_orders.nunique())\n",
    "print(df_orders.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming estimated arrival as estimated_arrival\n",
    "df_orders.rename(columns={'estimated arrival': 'estimated_arrival'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimated arrival column made to int data type\n",
    "df_orders['estimated_arrival'] = df_orders['estimated_arrival'].str.replace('\\D', '', regex=True)\n",
    "df_orders['estimated_arrival'] = df_orders['estimated_arrival'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing transactions that happened in the future\n",
    "today = str(date.today())\n",
    "df_orders = df_orders[df_orders['transaction_date'] <= today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order data cleaned completely, to check:\n",
    "print(df_orders.shape)\n",
    "print(df_orders.nunique())\n",
    "print(df_orders.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning order delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning order delays\n",
    "df_delays = all['order_delays.html'][0]\n",
    "\n",
    "print(df_delays.shape)\n",
    "print(df_delays.nunique())\n",
    "print(df_delays.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing useless Unnamed: 0 column\n",
    "df_delays = df_delays.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order data cleaned completely, to check:\n",
    "print(df_delays.shape)\n",
    "print(df_delays.nunique())\n",
    "print(df_delays.isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
